{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO/1FG+MoIrGE1DrLdeuMTE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"ZKR-M7hNyKVv","executionInfo":{"status":"ok","timestamp":1701810404360,"user_tz":360,"elapsed":6,"user":{"displayName":"Clay Roberts","userId":"15262378552571056378"}}},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from torchvision.transforms import functional as F\n","from PIL import Image\n","import cv2\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5\n","%cd yolov5\n","!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"8Yt4TqTIyv8f","executionInfo":{"status":"error","timestamp":1701810352686,"user_tz":360,"elapsed":557,"user":{"displayName":"Clay Roberts","userId":"15262378552571056378"}},"outputId":"b949e25a-173e-49df-c72d-aa3253aacfd2"},"execution_count":3,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-a75ce4f2d2e8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m net = cv.dnn.readNet(\"D:\\OPEN CV\\YOLOV object detection\\yolov3.weights\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                      \"D:\\OPEN CV\\YOLOV object detection\\yolov3.cfg\")\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cocc.names\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/dnn/src/darknet/darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: D:\\OPEN CV\\YOLOV object detection\\yolov3.cfg in function 'readNetFromDarknet'\n"]}]},{"cell_type":"code","source":["import torch\n","from yolov5.models.yolo import Model\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True).to(device)\n","model.eval()"],"metadata":{"id":"NqZbA1RvzRFn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","  ''')\n","  display(js)\n","  data = eval_js('takePhoto({})'.format(quality))\n","  binary = b64decode(data.split(',')[1])\n","  with open(filename, 'wb') as f:\n","    f.write(binary)\n","  return filename"],"metadata":{"id":"iZwL9i0Uzkyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_path = take_photo()"],"metadata":{"id":"LfqFjWvTzrJS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_image(image_path):\n","    image = Image.open(image_path)\n","    image_tensor = F.to_tensor(image)\n","    return image_tensor.unsqueeze(0).to(device)"],"metadata":{"id":"u34VYA0TzuC7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_tensor = preprocess_image(image_path)\n","outputs = model(image_tensor)[0]"],"metadata":{"id":"Oj79RYXVzwAn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def draw_boxes(image_path, outputs, threshold=0.3):\n","    image = cv2.imread(image_path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    h, w, _ = image.shape\n","\n","    for box in outputs:\n","        score, label, x1, y1, x2, y2 = box[4].item(), int(box[5].item()), box[0].item(), box[1].item(), box[2].item(), box[3].item()\n","        if score > threshold:\n","            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n","            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n","            text = f\"{model.names[label]:s}: {score:.2f}\"\n","            cv2.putText(image, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n","\n","    return image"],"metadata":{"id":"nWzuXHQpzyug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from yolov5.utils.general import non_max_suppression\n","image_tensor = preprocess_image(image_path)\n","outputs = model(image_tensor)\n","outputs = non_max_suppression(outputs)[0]"],"metadata":{"id":"yltoqHoBz05D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_image = draw_boxes(image_path, outputs)\n","cv2_imshow(result_image)"],"metadata":{"id":"a3LmtHbTz1zK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3tpb-6VXz33N"},"execution_count":null,"outputs":[]}]}